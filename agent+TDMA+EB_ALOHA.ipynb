{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 535,
      "metadata": {
        "id": "ZH0EFBY1Q2qF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Dropout, Input, Add, Activation, BatchNormalization\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.initializers import glorot_normal\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 536,
      "metadata": {
        "id": "rNfH9X9nCQZj"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_NAME = 'agent+TDMA+EB_ALOHA'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6CcCuj8JQEA_"
      },
      "source": [
        "## Fix random seed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 537,
      "metadata": {
        "id": "M5ivJuAQQCx3"
      },
      "outputs": [],
      "source": [
        "def same_seeds(seed):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "\n",
        "same_seeds(48763)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7dlFkYONQ2qJ"
      },
      "source": [
        "# DQN_brain\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 538,
      "metadata": {
        "id": "C0DeJwXCQ2qK"
      },
      "outputs": [],
      "source": [
        "class DQN:\n",
        "    def __init__(self,\n",
        "                 state_size,\n",
        "                 n_actions,\n",
        "                 memory_size=500,\n",
        "                 replace_target_iter=200,\n",
        "                 batch_size=32,\n",
        "                 learning_rate=0.01,\n",
        "                 gamma=0.9,\n",
        "                 epsilon=1,\n",
        "                 epsilon_min=0.01,\n",
        "                 epsilon_decay=0.995\n",
        "                 ):\n",
        "        # hyper-parameters\n",
        "        self.state_size = state_size\n",
        "        self.n_actions = n_actions\n",
        "        self.memory_size = memory_size\n",
        "        self.replace_target_iter = replace_target_iter\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.memory = np.zeros((self.memory_size, self.state_size * 2 + 2))\n",
        "        # temporary parameters\n",
        "        self.learn_step_counter = 0\n",
        "        self.memory_couter = 0\n",
        "\n",
        "        # build model\n",
        "        self.model = self.build_ResNet_model()  # model: evaluate Q value\n",
        "        self.target_model = self.build_ResNet_model()  # target_mode: target network\n",
        "\n",
        "    def build_ResNet_model(self):\n",
        "        inputs = Input(shape=(self.state_size, ))\n",
        "        h1 = Dense(64, activation=\"relu\",\n",
        "                   kernel_initializer='glorot_normal')(inputs)  # h1\n",
        "        h2 = Dense(64, activation=\"relu\",\n",
        "                   kernel_initializer='glorot_normal')(h1)  # h2\n",
        "\n",
        "        h3 = Dense(64, activation=\"relu\",\n",
        "                   kernel_initializer='glorot_normal')(h2)  # h3\n",
        "        h4 = Dense(64, activation=\"relu\",\n",
        "                   kernel_initializer='glorot_normal')(h3)  # h4\n",
        "        add1 = Add()([h4, h2])\n",
        "\n",
        "        h5 = Dense(64, activation=\"relu\",\n",
        "                   kernel_initializer='glorot_normal')(add1)  # h5\n",
        "        h6 = Dense(64, activation=\"relu\",\n",
        "                   kernel_initializer='glorot_normal')(h5)  # h6\n",
        "        add2 = Add()([h6, add1])\n",
        "\n",
        "        outputs = Dense(\n",
        "            self.n_actions, kernel_initializer='glorot_normal')(add2)\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(loss=\"mse\", optimizer=RMSprop(\n",
        "            learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        # Apply epsilon-greedy algorithm\n",
        "        state = state[np.newaxis, :]\n",
        "        self.epsilon *= self.epsilon_decay\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
        "\n",
        "        if np.random.random() < self.epsilon:\n",
        "            return np.random.randint(0, self.n_actions)\n",
        "\n",
        "        action_values = self.model.predict(state)\n",
        "        return np.argmax(action_values)\n",
        "\n",
        "    def store_transition(self, s, a, r, s_):\n",
        "        # s_: next_state\n",
        "        # r: ndarray or int\n",
        "        if np.isscalar(r):\n",
        "            r = [r]\n",
        "        if not hasattr(self, 'memory_couter'):\n",
        "            self.memory_couter = 0\n",
        "        transition = np.concatenate((s, [a], r, s_))\n",
        "        index = self.memory_couter % self.memory_size\n",
        "        self.memory[index, :] = transition\n",
        "        self.memory_couter += 1\n",
        "\n",
        "    def repalce_target_parameters(self):\n",
        "        weights = self.model.get_weights()\n",
        "        self.target_model.set_weights(weights)\n",
        "\n",
        "    def learn(self):\n",
        "        # check to update target netowrk parameters\n",
        "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
        "            self.repalce_target_parameters()  # iterative target model\n",
        "        self.learn_step_counter += 1\n",
        "\n",
        "        # sample batch memory from all memory\n",
        "        if self.memory_couter > self.memory_size:\n",
        "            sample_index = np.random.choice(\n",
        "                self.memory_size, size=self.batch_size)\n",
        "        else:\n",
        "            sample_index = np.random.choice(\n",
        "                self.memory_couter, size=self.batch_size)\n",
        "        batch_memory = self.memory[sample_index, :]\n",
        "\n",
        "        # batch memory row: [s, a, r, s_]\n",
        "        # number of batch memory: batch size\n",
        "        state = batch_memory[:, :self.state_size]\n",
        "        action = batch_memory[:, self.state_size].astype(int)  # float -> int\n",
        "        reward = batch_memory[:, self.state_size]\n",
        "        next_state = batch_memory[:, -self.state_size:]\n",
        "\n",
        "        q = self.model.predict(state)  # state\n",
        "        q_targ = self.target_model.predict(next_state)  # next state\n",
        "\n",
        "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
        "        q[batch_index, action] = reward + self.gamma * np.max(q_targ, axis=1)\n",
        "\n",
        "        self.model.fit(state, q, self.batch_size, epochs=1, verbose=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TDMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 539,
      "metadata": {
        "id": "aIdP9E3zB2_g"
      },
      "outputs": [],
      "source": [
        "class TDMA:\n",
        "    def __init__(self, n_nodes, action_list_len, n_slot_used):\n",
        "        # n_actions=2: (wait, transmit)\n",
        "        # action_list_len and n_slot_used indicate the parameters of ONE node.\n",
        "        self.n_nodes = n_nodes\n",
        "        self.action_list_len = action_list_len\n",
        "        self.n_slot_used = n_slot_used\n",
        "        self.action_list = self.__create_action_list__()\n",
        "        self.counter = 0\n",
        "\n",
        "    def __create_action_list__(self):  # (node, action_list)\n",
        "        action_list = np.zeros((self.n_nodes, self.action_list_len))\n",
        "        for i in range(self.n_nodes):\n",
        "            idx = np.random.randint(\n",
        "                self.action_list_len, size=self.n_slot_used)\n",
        "            action_list[i, idx] = 1\n",
        "        return action_list\n",
        "\n",
        "    def tic(self):  # 1D: action of each node\n",
        "        tdma_action = self.action_list[:, self.counter]\n",
        "        # tdma_action = np.squeeze(tdma_action)\n",
        "        self.counter += 1\n",
        "        if self.counter == len(self.action_list):\n",
        "            self.counter = 0\n",
        "        return tdma_action.astype(np.int32)\n",
        "\n",
        "    def reset(self, n_slot_used):  # Change the action pattern.\n",
        "        self.n_slot_used = n_slot_used\n",
        "        self.action_list = self.__create_action_list__()\n",
        "        self.counter = 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exponential-backoff ALOHA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 540,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EB_ALOHA:\n",
        "    def __init__(self, n_nodes, Wmin=2, max_backoff=2):\n",
        "        # n_actions=2: (wait, transmit)\n",
        "        # state_size and n_slot_used indicate the parameters of ONE node.\n",
        "        self.n_nodes = n_nodes\n",
        "        self.max_backoff = max_backoff\n",
        "        self.Wmin = Wmin\n",
        "        self.actions = np.zeros(self.n_nodes)\n",
        "\n",
        "        self.count = np.zeros(self.n_nodes)\n",
        "        self.backoff = np.random.randint(\n",
        "            0, self.Wmin * 2**self.count, size=self.n_nodes)\n",
        "\n",
        "    def tic(self):\n",
        "        self.count = np.minimum(self.count, self.max_backoff)\n",
        "        self.backoff -= 1\n",
        "\n",
        "        filter_arr = self.backoff < 0\n",
        "        filter_arr = np.arange(self.n_nodes, dtype=np.int32)[filter_arr]\n",
        "        self.backoff[filter_arr] = np.random.randint(\n",
        "            0, self.Wmin * 2**self.count)[filter_arr]\n",
        "\n",
        "        aloha_actions = (self.backoff == 0)\n",
        "        aloha_actions = aloha_actions.astype(np.int32)\n",
        "        self.actions = aloha_actions\n",
        "        return aloha_actions  # return 1 if timeout\n",
        "    \n",
        "    def handle_collision(self):\n",
        "        filter_arr = (self.actions==1)\n",
        "        self.count += filter_arr.astype(np.int32)\n",
        "\n",
        "    def reset(self):  # Change the action pattern.\n",
        "        self.count = np.zeros(self.n_nodes)\n",
        "        self.backoff = np.random.randint(\n",
        "            0, self.Wmin * 2**self.count, size=self.n_nodes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bdSfcoDnQ2qM"
      },
      "source": [
        "# Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 541,
      "metadata": {
        "id": "ZGZtSDMuQ2qM"
      },
      "outputs": [],
      "source": [
        "class ENVIRONMENT:\n",
        "    def __init__(self, state_size=10, n_TDMA=1, n_EB_ALOHA=1):\n",
        "        self.n_TDMA = n_TDMA\n",
        "        self.n_EB_ALOHA = n_EB_ALOHA\n",
        "        self.state_size = state_size\n",
        "        self.TDMA_nodes = TDMA(n_TDMA, 14, 6)\n",
        "        self.EB_ALOHA_nodes = EB_ALOHA(n_EB_ALOHA, Wmin=2, max_backoff=2)\n",
        "\n",
        "    def reset(self):\n",
        "        self.TDMA_nodes.reset(6)\n",
        "        self.EB_ALOHA_nodes.reset()\n",
        "        init_state = np.zeros(self.state_size)\n",
        "        return init_state\n",
        "\n",
        "    def step(self, action):\n",
        "        agent_reward = 0\n",
        "        tdma_reward = np.zeros(self.n_TDMA)\n",
        "        aloha_reward = np.zeros(self.n_EB_ALOHA)\n",
        "        reward = 0\n",
        "        observation_ = 0\n",
        "        tdma_actions = np.zeros(self.n_TDMA, dtype=np.int32)\n",
        "        aloha_actions = np.zeros(self.n_EB_ALOHA, dtype=np.int32)\n",
        "        if self.n_TDMA > 0:\n",
        "            tdma_actions = self.TDMA_nodes.tic()\n",
        "        if self.n_EB_ALOHA > 0:\n",
        "            aloha_actions = self.EB_ALOHA_nodes.tic()\n",
        "\n",
        "        if action == 1:\n",
        "            if np.sum(tdma_actions)+np.sum(aloha_actions) > 0:  # collision\n",
        "                observation_ = 'F'  # tx, no success\n",
        "            else:  # agent success\n",
        "                reward = 1\n",
        "                agent_reward = 1\n",
        "                observation_ = 'S'  # tx, success\n",
        "        else:\n",
        "            if tdma_actions.all(0) and aloha_actions.all(0):  # idle\n",
        "                observation_ = 'I'\n",
        "            elif np.sum(tdma_actions)+np.sum(aloha_actions) == 1:  # some node success\n",
        "                reward = 1\n",
        "                tdma_reward = tdma_actions\n",
        "                aloha_reward = aloha_actions\n",
        "                observation_ = 'B'\n",
        "            else:  # some node collide\n",
        "                observation_ = 'B'\n",
        "\n",
        "        return observation_, reward, agent_reward, tdma_reward, aloha_reward"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TWDuuALSQ2qN"
      },
      "source": [
        "# Run DQN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 542,
      "metadata": {},
      "outputs": [],
      "source": [
        "# n_DQN = 1\n",
        "M = 20  # state length\n",
        "E = 500  # memory size\n",
        "F = 20  # target network update frequency\n",
        "B = 32  # mini-batch size\n",
        "\n",
        "n_TDMA = 1\n",
        "n_EB_ALOHA = 0\n",
        "\n",
        "env = ENVIRONMENT(state_size=int(8*M), n_TDMA=n_TDMA, n_EB_ALOHA=n_EB_ALOHA)\n",
        "\n",
        "dqn_agent = DQN(env.state_size,\n",
        "                2,\n",
        "                memory_size=E,\n",
        "                replace_target_iter=F,\n",
        "                batch_size=B,\n",
        "                learning_rate=0.01,\n",
        "                gamma=0.9,\n",
        "                epsilon=0.5,\n",
        "                epsilon_min=0.005,\n",
        "                epsilon_decay=0.995,\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 543,
      "metadata": {
        "id": "ox4ptx1GQ2qN"
      },
      "outputs": [],
      "source": [
        "def return_action(action, n_actions=2):\n",
        "    one_hot_vector = [0] * n_actions\n",
        "    one_hot_vector[action] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "\n",
        "def return_observation(o):\n",
        "    if o == 'S':\n",
        "        return [1, 0, 0, 0]\n",
        "    elif o == 'F':\n",
        "        return [0, 1, 0, 0]\n",
        "    elif o == 'B':\n",
        "        return [0, 0, 1, 0]\n",
        "    elif o == 'I':\n",
        "        return [0, 0, 0, 1]\n",
        "\n",
        "\n",
        "def main(max_iter):\n",
        "    agent_reward_list = []\n",
        "    tdma_reward_list = []\n",
        "    aloha_reward_list = []\n",
        "    state = env.reset()\n",
        "    print('------------------------------------------')\n",
        "    print('---------- Start processing ... ----------')\n",
        "    print('------------------------------------------')\n",
        "\n",
        "    for i in tqdm(range(max_iter)):\n",
        "        agent_action = dqn_agent.choose_action(state)\n",
        "        observation_, reward, agent_reward, tdma_reward, aloha_reward = env.step(\n",
        "            agent_action)\n",
        "        agent_reward_list.append(agent_reward)\n",
        "        tdma_reward_list.append(tdma_reward)\n",
        "        aloha_reward_list.append(aloha_reward)\n",
        "\n",
        "        # state = (action_t, observation_t)\n",
        "        next_state = np.concatenate((state[8:], np.array(return_action(\n",
        "            agent_action)+return_observation(observation_) + [agent_reward, np.sum(tdma_reward)+np.sum(aloha_reward)]))).astype(np.int32)\n",
        "        dqn_agent.store_transition(state, agent_action, reward, next_state)\n",
        "        if i > 100:\n",
        "            dqn_agent.learn()       # internally iterates default (prediction) model\n",
        "        state = next_state\n",
        "    if not os.path.isdir('./rewards'):\n",
        "        os.mkdir('./rewards')\n",
        "    np.save(f'./rewards/{EXPERIMENT_NAME}_agent', np.array(agent_reward_list))\n",
        "    if n_TDMA >0:\n",
        "        np.save(f'./rewards/{EXPERIMENT_NAME}_tdma', np.array(tdma_reward_list))\n",
        "    if n_EB_ALOHA>0:\n",
        "        np.save(f'./rewards/{EXPERIMENT_NAME}_aloha', np.array(aloha_reward_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 544,
      "metadata": {
        "id": "IzAbJ_XyQ2qO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------\n",
            "---------- Start processing ... ----------\n",
            "------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 2/100 [00:00<00:07, 12.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 4/100 [00:00<00:08, 10.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 6/100 [00:00<00:07, 12.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 9/100 [00:00<00:05, 16.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 11/100 [00:00<00:05, 17.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 14/100 [00:00<00:04, 19.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:00<00:03, 23.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 21/100 [00:01<00:03, 21.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:01<00:02, 34.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [00:01<00:01, 35.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 38/100 [00:01<00:01, 37.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:01<00:01, 30.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 46/100 [00:01<00:01, 28.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 50/100 [00:02<00:02, 22.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 53/100 [00:02<00:02, 20.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 56/100 [00:02<00:02, 20.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 59/100 [00:02<00:02, 18.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 61/100 [00:02<00:02, 17.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 63/100 [00:02<00:02, 17.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 65/100 [00:03<00:02, 17.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 68/100 [00:03<00:01, 19.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 71/100 [00:03<00:01, 21.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 74/100 [00:03<00:01, 19.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 77/100 [00:03<00:01, 21.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 80/100 [00:03<00:01, 19.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 86/100 [00:03<00:00, 22.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 90/100 [00:04<00:00, 22.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 93/100 [00:04<00:00, 22.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 97/100 [00:04<00:00, 25.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 22.28it/s]\n"
          ]
        }
      ],
      "source": [
        "main(max_iter=10000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eTEze5yDQ2qP"
      },
      "source": [
        "# Average_throughput\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 545,
      "metadata": {
        "id": "FLbAOcM8Q2qP"
      },
      "outputs": [],
      "source": [
        "def plot_avg_throughput(file1, file2, file3):\n",
        "    max_iter = 10000\n",
        "    N = 1000\n",
        "\n",
        "    # load reward\n",
        "    agent1_reward = np.load(file1)\n",
        "    agent2_reward = np.load(file2)[:,0]\n",
        "    agent3_reward = np.load(file3)[:,0]\n",
        "\n",
        "    avg_throughput_agent1 = np.zeros((1, max_iter))\n",
        "    avg_throughput_agent2 = np.zeros((1, max_iter))\n",
        "    avg_throughput_agent3 = np.zeros((1, max_iter))\n",
        "\n",
        "    agent1_temp_sum = 0\n",
        "    agent2_temp_sum = 0\n",
        "    agent3_temp_sum = 0\n",
        "    for i in range(0, max_iter):\n",
        "        if i < N:\n",
        "            agent1_temp_sum += agent1_reward[i]\n",
        "            avg_throughput_agent1[0][i] = agent1_temp_sum / (i+1)\n",
        "            agent2_temp_sum += agent2_reward[i]\n",
        "            avg_throughput_agent2[0][i] = agent2_temp_sum / (i+1)\n",
        "            agent3_temp_sum += agent3_reward[i]\n",
        "            avg_throughput_agent3[0][i] = agent3_temp_sum / (i+1)\n",
        "        else:\n",
        "            agent1_temp_sum += agent1_reward[i] - agent1_reward[i-N]\n",
        "            avg_throughput_agent1[0][i] = agent1_temp_sum / N\n",
        "            agent2_temp_sum += agent2_reward[i] - agent2_reward[i-N]\n",
        "            avg_throughput_agent2[0][i] = agent2_temp_sum / N\n",
        "            agent3_temp_sum += agent3_reward[i] - agent3_reward[i-N]\n",
        "            avg_throughput_agent3[0][i] = agent3_temp_sum / N\n",
        "\n",
        "    plt.xlim((0, max_iter))\n",
        "    plt.ylim((-0.05, 1))\n",
        "\n",
        "    agent1_line, = plt.plot(\n",
        "        avg_throughput_agent1[0], color='r', lw=1.2, label='agent')\n",
        "    agent2_line, = plt.plot(\n",
        "        avg_throughput_agent2[0], color='g', lw=1.2, label='tdma')\n",
        "    agent3_line, = plt.plot(\n",
        "        avg_throughput_agent3[0], color='b', lw=1.2, label='em-aloha')\n",
        "\n",
        "    plt.grid()\n",
        "    plt.legend(handles=[agent1_line, agent2_line, agent3_line], loc='best')\n",
        "    plt.xlabel(\"iteration\")\n",
        "    plt.ylabel(\"average throughput\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 546,
      "metadata": {
        "id": "vjJ1t9fAQ2qP"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'rewards/agent+TDMA_20_aloha.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[546], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m fig1 \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m----> 2\u001b[0m plot_avg_throughput(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrewards/\u001b[39;49m\u001b[39m{\u001b[39;49;00mEXPERIMENT_NAME\u001b[39m}\u001b[39;49;00m\u001b[39m_agent.npy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m                     \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrewards/\u001b[39;49m\u001b[39m{\u001b[39;49;00mEXPERIMENT_NAME\u001b[39m}\u001b[39;49;00m\u001b[39m_tdma.npy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m                     \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrewards/\u001b[39;49m\u001b[39m{\u001b[39;49;00mEXPERIMENT_NAME\u001b[39m}\u001b[39;49;00m\u001b[39m_aloha.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
            "Cell \u001b[1;32mIn[545], line 8\u001b[0m, in \u001b[0;36mplot_avg_throughput\u001b[1;34m(file1, file2, file3)\u001b[0m\n\u001b[0;32m      6\u001b[0m agent1_reward \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(file1)\n\u001b[0;32m      7\u001b[0m agent2_reward \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(file2)[:,\u001b[39m0\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m agent3_reward \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(file3)[:,\u001b[39m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m avg_throughput_agent1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, max_iter))\n\u001b[0;32m     11\u001b[0m avg_throughput_agent2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, max_iter))\n",
            "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rewards/agent+TDMA_20_aloha.npy'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig1 = plt.figure()\n",
        "plot_avg_throughput(f'rewards/{EXPERIMENT_NAME}_agent.npy',\n",
        "                    f'rewards/{EXPERIMENT_NAME}_tdma.npy',\n",
        "                    f'rewards/{EXPERIMENT_NAME}_aloha.npy')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
